{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import py_vncorenlp\n", "import os\n", "from sentence_transformers import SentenceTransformer\n", "from sklearn.feature_extraction.text import CountVectorizer\n", "from sklearn.metrics.pairwise import cosine_similarity"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["stop_words = []\n", "with open('vietnamese-stopwords.txt', encoding='utf8') as f:\n", "    for line in f:\n", "        stop_words.append(line.strip())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["doc = ''\n", "with open('input_line.txt', encoding='utf8') as f:\n", "    doc = f.read()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def removeStopWords(o_sen):\n", "    words = [word for word in o_sen.split() if word not in stop_words]\n", "    return \" \".join(words)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_dir = os.path.abspath('./vncorenlp')\n", "if not os.path.exists(model_dir):\n", "    os.makedirs(model_dir)\n", "# py_vncorenlp.download_model(save_dir=os.path.abspath('./vncorenlp'))\n", "py_vncorenlp.download_model(save_dir=model_dir)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Load the word and sentence segmentation component"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rdrsegmenter = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\"], save_dir=model_dir)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["doc_segmented = rdrsegmenter.word_segment(doc)\n", "# Extract candidate words/phrases"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["count = CountVectorizer(ngram_range=(1, 1)).fit(\n", "    [removeStopWords(doc_segmented[0])])\n", "candidates = count.get_feature_names()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model = SentenceTransformer('distiluse-base-multilingual-cased-v2')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["doc_embedding = model.encode([doc])\n", "candidate_embeddings = model.encode(candidates)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["top_n = 10\n", "distances = cosine_similarity(doc_embedding, candidate_embeddings)\n", "keywords = [candidates[index] for index in distances.argsort()[0][-top_n:]]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(keywords)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}